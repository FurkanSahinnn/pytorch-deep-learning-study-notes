{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6645fd8",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network:\n",
    "RNN, sırayla gelen verileri işleyen bir modeldir. Her bir adımda bir kelimenin bilgisine önceki adımdan gelen kelimelerin bilgisini ekleyerek sequential\n",
    "bir şekilde gider. Her bir kelime işlenirken hidden state adı verilen hafıza hücrelerinde önceki ve o anki kelimenin özet bilgilerini tutar.\n",
    "\n",
    "```python\n",
    "h_t = f(W_x * x_t + W_h * h_{t + 1} + b)\n",
    "```\n",
    "\n",
    "* **h_t:** Şu anki hidden state\n",
    "* **x_t:** Şu anki kelimenin embedding vektörü\n",
    "* **h_{t + 1}:** Önceki adımdaki hidden state\n",
    "* **W_x ve W_h:** Ağırlıklar.\n",
    "* **b:** Bias\n",
    "* **f:** Activation function.\n",
    "\n",
    "**Not:** Başlangıç hidden state'inin (h_0) değeri gelende 0 olarak başlatılır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d6a2b",
   "metadata": {},
   "source": [
    "Amacımız Premise ve Hypothesis arasındaki ilişkiyi tahmin etmek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9877f0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d3bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = \"data/nli_tr/snli_tr_train.csv\"\n",
    "val_path = \"data/nli_tr/snli_tr_validation.csv\"\n",
    "test_path = \"data/nli_tr/snli_tr_test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path, sep=',')\n",
    "val_df = pd.read_csv(val_path, sep=',')\n",
    "test_df = pd.read_csv(test_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d5350c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['idx', 'premise', 'hypothesis', 'label'], dtype='object'),\n",
       " Index(['idx', 'premise', 'hypothesis', 'label'], dtype='object'),\n",
       " Index(['idx', 'premise', 'hypothesis', 'label'], dtype='object'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns, val_df.columns, test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02644444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((550152, 4), (10000, 4), (10000, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e42fc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Attaki bir kişi, bozuk bir uçağın üzerinden at...</td>\n",
       "      <td>Bir kişi atını yarışma için eğitiyor.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Attaki bir kişi, bozuk bir uçağın üzerinden at...</td>\n",
       "      <td>Bir kişi bir lokantada omlet sipariş ediyor.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Attaki bir kişi, bozuk bir uçağın üzerinden at...</td>\n",
       "      <td>Bir kişi açık havada, at üzerinde.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fotoğraf makinesinde gülümseyen ve sallayan ço...</td>\n",
       "      <td>Ailelerine gülümsüyorlar.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Fotoğraf makinesinde gülümseyen ve sallayan ço...</td>\n",
       "      <td>Burada çocuklar var.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                            premise  \\\n",
       "0    0  Attaki bir kişi, bozuk bir uçağın üzerinden at...   \n",
       "1    1  Attaki bir kişi, bozuk bir uçağın üzerinden at...   \n",
       "2    2  Attaki bir kişi, bozuk bir uçağın üzerinden at...   \n",
       "3    3  Fotoğraf makinesinde gülümseyen ve sallayan ço...   \n",
       "4    4  Fotoğraf makinesinde gülümseyen ve sallayan ço...   \n",
       "\n",
       "                                     hypothesis  label  \n",
       "0         Bir kişi atını yarışma için eğitiyor.      1  \n",
       "1  Bir kişi bir lokantada omlet sipariş ediyor.      2  \n",
       "2            Bir kişi açık havada, at üzerinde.      0  \n",
       "3                     Ailelerine gülümsüyorlar.      1  \n",
       "4                          Burada çocuklar var.      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb33129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop idx column\n",
    "train_df = train_df.drop(columns=['idx'])\n",
    "val_df = val_df.drop(columns=['idx'])\n",
    "test_df = test_df.drop(columns=['idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe51af31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       " 0    183416\n",
       " 2    183187\n",
       " 1    182764\n",
       "-1       785\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check label type\n",
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ecafd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hücre 14'ten sonra bu kodu ekleyin:\n",
    "def fix_labels(df):\n",
    "    \"\"\"Label'ları düzelt: -1 -> 0, 0 -> 1, 1 -> 2, 2 -> 3\"\"\"\n",
    "    df = df.copy()\n",
    "    label_mapping = {-1: 0, 0: 1, 1: 2, 2: 3}\n",
    "    df['label'] = df['label'].map(label_mapping)\n",
    "    return df\n",
    "\n",
    "train_df = fix_labels(train_df)\n",
    "val_df = fix_labels(val_df)\n",
    "test_df = fix_labels(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f231b133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Attaki bir kişi, bozuk bir uçağın üzerinden at...</td>\n",
       "      <td>Bir kişi atını yarışma için eğitiyor.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attaki bir kişi, bozuk bir uçağın üzerinden at...</td>\n",
       "      <td>Bir kişi bir lokantada omlet sipariş ediyor.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attaki bir kişi, bozuk bir uçağın üzerinden at...</td>\n",
       "      <td>Bir kişi açık havada, at üzerinde.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fotoğraf makinesinde gülümseyen ve sallayan ço...</td>\n",
       "      <td>Ailelerine gülümsüyorlar.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fotoğraf makinesinde gülümseyen ve sallayan ço...</td>\n",
       "      <td>Burada çocuklar var.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Attaki bir kişi, bozuk bir uçağın üzerinden at...   \n",
       "1  Attaki bir kişi, bozuk bir uçağın üzerinden at...   \n",
       "2  Attaki bir kişi, bozuk bir uçağın üzerinden at...   \n",
       "3  Fotoğraf makinesinde gülümseyen ve sallayan ço...   \n",
       "4  Fotoğraf makinesinde gülümseyen ve sallayan ço...   \n",
       "\n",
       "                                     hypothesis  label  \n",
       "0         Bir kişi atını yarışma için eğitiyor.      2  \n",
       "1  Bir kişi bir lokantada omlet sipariş ediyor.      3  \n",
       "2            Bir kişi açık havada, at üzerinde.      1  \n",
       "3                     Ailelerine gülümsüyorlar.      2  \n",
       "4                          Burada çocuklar var.      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "860c3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NLIDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.premises = df['premise'].tolist()\n",
    "        self.hypotheses = df['hypothesis'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        premise = self.premises[idx]\n",
    "        hypothesis = self.hypotheses[idx]\n",
    "        label = self.labels[idx]\n",
    "        return premise, hypothesis, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2e1d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = NLIDataset(train_df)\n",
    "test_dataset = NLIDataset(test_df)\n",
    "val_dataset = NLIDataset(val_df)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f379a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/legacies/anaconda3/envs/torch_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5733d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "791340d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, hidden_size=128, num_classes=4, freeze_bert=True):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained('dbmdz/bert-base-turkish-uncased')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('dbmdz/bert-base-turkish-uncased')\n",
    "        \n",
    "        embedding_dim = self.bert.config.hidden_size # 768 for BERT base\n",
    "        \n",
    "        self.rnn_premise = nn.RNN(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
    "        self.rnn_hypothesis = nn.RNN(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
    "        \n",
    "        # Concatenate the outputs of both RNNs and classify using a fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        \n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def encode(self, texts):\n",
    "        inputs = self.tokenizer(\n",
    "            texts, \n",
    "            return_tensors='pt', \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "        \n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "        return embeddings\n",
    "    \n",
    "    def forward(self, premise_list, hypothesis_list):\n",
    "        # Encode premises and hypotheses\n",
    "        premise_embeddings = self.encode(premise_list)\n",
    "        hypothesis_embeddings = self.encode(hypothesis_list)\n",
    "        \n",
    "        # Pass through RNNs\n",
    "        rnn_out_premise, _ = self.rnn_premise(premise_embeddings)\n",
    "        rnn_out_hypothesis, _ = self.rnn_hypothesis(hypothesis_embeddings)\n",
    "        \n",
    "        # Take the last hidden state from both RNNs\n",
    "        last_hidden_premise = rnn_out_premise[:, -1, :]\n",
    "        last_hidden_hypothesis = rnn_out_hypothesis[:, -1, :]\n",
    "        \n",
    "        # Concatenate the outputs\n",
    "        combined = torch.cat((last_hidden_premise, last_hidden_hypothesis), dim=1)\n",
    "        \n",
    "        # Fully connected layer for classification\n",
    "        logits = self.fc(combined)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa05855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = RNNModel(num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9d3e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Attaki bir kişi, bozuk bir uçağın üzerinden atlar.',\n",
       " 'Bir kişi atını yarışma için eğitiyor.',\n",
       " 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0]  # Example to check if the dataset works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1025b0a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m premises, hypotheses, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     11\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpremises\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypotheses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[14], line 38\u001b[0m, in \u001b[0;36mRNNModel.forward\u001b[0;34m(self, premise_list, hypothesis_list)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, premise_list, hypothesis_list):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Encode premises and hypotheses\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     premise_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(premise_list)\n\u001b[0;32m---> 38\u001b[0m     hypothesis_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhypothesis_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Pass through RNNs\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     rnn_out_premise, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_premise(premise_embeddings)\n",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m, in \u001b[0;36mRNNModel.encode\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts):\n\u001b[1;32m     20\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[1;32m     21\u001b[0m         texts, \n\u001b[1;32m     22\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m         max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m\n\u001b[1;32m     26\u001b[0m     )\n\u001b[0;32m---> 28\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training loop ---\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for premises, hypotheses, labels in train_loader:\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(premises, hypotheses)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item() * labels.size(0)\n",
    "        \n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        correct_train += (pred == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "    avg_train_loss = total_train_loss / total_train\n",
    "    train_accuracy = correct_train / total_train\n",
    "    \n",
    "    # --- Validation loop ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for premises, hypotheses, labels in val_loader:\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(premises, hypotheses)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_val_loss += loss.item() * labels.size(0)\n",
    "            \n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            correct_val += (pred == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "            \n",
    "    avg_val_loss = total_val_loss / total_val\n",
    "    val_accuracy = correct_val / total_val\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Testing loop ---\n",
    "print(\"=== Testing Evaluation ===\")\n",
    "model.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for premises, hypotheses, labels in test_loader:\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(premises, hypotheses)\n",
    "        \n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        correct_test += (pred == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "test_accuracy = correct_test / total_test\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"=== Testing Evaluation Completed ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
